{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This is a project for medical 3d voxel classification mission for machine learning course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as udata\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Ultra parameters definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "First read data from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7778f77b820541b99651d6544225267c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='reading', max=584, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "voxel_train = []\n",
    "seg_train = []\n",
    "for i in tqdm_notebook(range(584), desc='reading'):\n",
    "    try:\n",
    "        data = np.load('data/train_val/candidate{}.npz'.format(i))\n",
    "    except FileNotFoundError:\n",
    "        continue\n",
    "    try:\n",
    "        voxel_train = np.append(voxel_train, np.expand_dims(data['voxel'], axis=0), axis=0)\n",
    "        seg_train = np.append(seg_train, np.expand_dims(data['seg'], axis=0), axis=0)\n",
    "    except ValueError:\n",
    "        voxel_train = np.expand_dims(data['voxel'], axis=0)\n",
    "        seg_train = np.expand_dims(data['seg'], axis=0)\n",
    "training_batch_size = voxel_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "864d34240dfd428895d645a18ffd64fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='reading', max=584, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "voxel_test = []\n",
    "seg_test = []\n",
    "for i in tqdm_notebook(range(584), desc='reading'):\n",
    "    try:\n",
    "        data = np.load('data/test/candidate{}.npz'.format(i))\n",
    "    except FileNotFoundError:\n",
    "        continue\n",
    "    try:\n",
    "        voxel_test = np.append(voxel_test, np.expand_dims(data['voxel'], axis=0), axis=0)\n",
    "        seg_test = np.append(seg_test, np.expand_dims(data['seg'], axis=0), axis=0)\n",
    "    except ValueError:\n",
    "        voxel_test = np.expand_dims(data['voxel'], axis=0)\n",
    "        seg_test = np.expand_dims(data['seg'], axis=0)\n",
    "test_batch_size = voxel_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_label = pd.read_csv('data/train_val.csv').values[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "Next we process the data we get, then transform them into tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.0 71.0 98.0\n"
     ]
    }
   ],
   "source": [
    "s_gap = np.zeros([training_batch_size])\n",
    "t_gap = np.zeros([training_batch_size])\n",
    "u_gap = np.zeros([training_batch_size])\n",
    "for i in range(training_batch_size):\n",
    "    s = np.argwhere(np.sum(np.sum(seg_train[i], axis=0), axis=1) != 0)\n",
    "    t = np.argwhere(np.sum(np.sum(seg_train[i], axis=0), axis=0) != 0)\n",
    "    u = np.argwhere(np.sum(np.sum(seg_train[i], axis=1), axis=1) != 0)\n",
    "    s_gap[i] = np.max(s) - np.min(s)\n",
    "    t_gap[i] = np.max(t) - np.min(t)\n",
    "    u_gap[i] = np.max(u) - np.min(u)\n",
    "print(np.max(s_gap), np.max(t_gap), np.max(u_gap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    voxel_train = torch.from_numpy(voxel_train).unsqueeze(1)\n",
    "    voxel_test = torch.from_numpy(voxel_test).unsqueeze(1)\n",
    "    seg_train = torch.from_numpy(seg_train).unsqueeze(1)\n",
    "    seg_test = torch.from_numpy(seg_test).unsqueeze(1)\n",
    "except TypeError:\n",
    "    pass\n",
    "masked_voxel_train = voxel_train.mul(seg_train)\n",
    "masked_voxel_test = voxel_test.mul(seg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Sum of input lengths does not equal the length of the input dataset!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-b5d3ec5db226>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mvalidation_batch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtraining_batch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtraining_batch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_batch_size\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mvalidation_batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmasked_voxel_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmasked_voxel_validate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mudata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmasked_voxel_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtraining_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_batch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mvoxel_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvoxel_validate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mudata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvoxel_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtraining_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_batch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmasked_voxel_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mudata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmasked_voxel_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\EE369\\lib\\site-packages\\torch\\utils\\data\\dataset.py\u001b[0m in \u001b[0;36mrandom_split\u001b[1;34m(dataset, lengths)\u001b[0m\n\u001b[0;32m    270\u001b[0m     \"\"\"\n\u001b[0;32m    271\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 272\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Sum of input lengths does not equal the length of the input dataset!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m     \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandperm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Sum of input lengths does not equal the length of the input dataset!"
     ]
    }
   ],
   "source": [
    "validation_batch_size = round(0.2 * training_batch_size)\n",
    "training_batch_size = training_batch_size - validation_batch_size\n",
    "masked_voxel_train, masked_voxel_validate = udata.random_split(masked_voxel_train, [training_batch_size, validation_batch_size])\n",
    "voxel_train, voxel_validate = udata.random_split(voxel_train, [training_batch_size, validation_batch_size])\n",
    "masked_voxel_loader = udata.DataLoader(masked_voxel_train, batch_size, shuffle=True)\n",
    "voxel_loader = udata.DataLoader(voxel_train, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "We can now build the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1152, 9, 9, 9])\n"
     ]
    }
   ],
   "source": [
    "class Stem(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Stem, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(1, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv3d(32, 32, kernel_size=3, stride=2)\n",
    "        self.conv3 = nn.Conv3d(32, 64, kernel_size=3)\n",
    "        self.conv4 = nn.Conv3d(64, 96, kernel_size=3, stride=2)\n",
    "        self.pool1 = nn.MaxPool3d(kernel_size=3, stride=2)\n",
    "        self.conv5 = nn.Conv3d(160, 64, kernel_size=1)\n",
    "        self.conv6 = nn.Conv3d(64, 96, kernel_size=3, padding=1)\n",
    "        self.conv7 = nn.Conv3d(160, 64, kernel_size=1)\n",
    "        self.conv8 = nn.Conv3d(64, 64, kernel_size=[5, 1, 1], padding=[2, 0, 0])\n",
    "        self.conv9 = nn.Conv3d(64, 64, kernel_size=[1, 5, 1], padding=[0, 2, 0])\n",
    "        self.conv10 = nn.Conv3d(64, 64, kernel_size=[1, 1, 5], padding=[0, 0, 2])\n",
    "        self.conv11 = nn.Conv3d(64, 96, kernel_size=3, padding=1)\n",
    "        self.conv12 = nn.Conv3d(192, 192, kernel_size=3)\n",
    "        self.pool2 = nn.MaxPool3d(kernel_size=3, stride=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x1 = self.conv4(x)\n",
    "        x2 = self.pool1(x)\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        x1 = self.conv5(x)\n",
    "        x1 = self.conv6(x1)\n",
    "        x2 = self.conv7(x)\n",
    "        x2 = self.conv8(x2)\n",
    "        x2 = self.conv9(x2)\n",
    "        x2 = self.conv10(x2)\n",
    "        x2 = self.conv11(x2)\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        x1 = self.conv12(x)\n",
    "        x2 = self.pool2(x)\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        return x\n",
    "        \n",
    "\n",
    "class InceptionA(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(InceptionA, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(384, 32, kernel_size=1)\n",
    "        self.conv2 = nn.Conv3d(384, 32, kernel_size=1)\n",
    "        self.conv3 = nn.Conv3d(32, 32, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv3d(384, 32, kernel_size=1)\n",
    "        self.conv5 = nn.Conv3d(32, 32, kernel_size=3, padding=1)\n",
    "        self.conv6 = nn.Conv3d(32, 32, kernel_size=3, padding=1)\n",
    "        self.conv7 = nn.Conv3d(96, 384, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.conv2(x)\n",
    "        x2 = self.conv3(x2)\n",
    "        x3 = self.conv4(x)\n",
    "        x3 = self.conv5(x3)\n",
    "        x3 = self.conv6(x3)\n",
    "        x4 = torch.cat((x1, x2, x3), dim=1)\n",
    "        x4 = self.conv7(x4)\n",
    "        x = x + x4\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class ReductionA(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ReductionA, self).__init__()\n",
    "        self.pool1 = nn.MaxPool3d(kernel_size=3, stride=2)\n",
    "        self.conv1 = nn.Conv3d(384, 384, kernel_size=3, stride=2)\n",
    "        self.conv2 = nn.Conv3d(384, 256, kernel_size=1)\n",
    "        self.conv3 = nn.Conv3d(256, 256, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv3d(256, 384, kernel_size=3, stride=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.pool1(x)\n",
    "        x2 = self.conv1(x)\n",
    "        x3 = self.conv2(x)\n",
    "        x3 = self.conv3(x3)\n",
    "        x3 = self.conv4(x3)\n",
    "        x = torch.cat((x1, x2, x3), dim=1)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class InceptionB(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(InceptionB, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(1152, 192, kernel_size=1)\n",
    "        self.conv2 = nn.Conv3d(1152, 128, kernel_size=1)\n",
    "        self.conv3 = nn.Conv3d(128, 192, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv3d(384, 1152, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.conv2(x)\n",
    "        x2 = self.conv3(x2)\n",
    "        x3 = torch.cat((x1, x2), dim=1)\n",
    "        x3 = self.conv4(x3)\n",
    "        x = x + x3\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class ReductionB(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ReductionB, self).__init__()\n",
    "        self.pool1 = nn.MaxPool3d(kernel_size=3, stride=2)\n",
    "        self.conv1 = nn.Conv3d(1152, 256, kernel_size=1)\n",
    "        self.conv2 = nn.Conv3d(256, 384, kernel_size=3, stride=2)\n",
    "        self.conv3 = nn.Conv3d(1152, 256, kernel_size=1)\n",
    "        self.conv4 = nn.Conv3d(256, 320, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv3d(320, 384, kernel_size=3, stride=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.pool1(x)\n",
    "        x2 = self.conv1(x)\n",
    "        x2 = self.conv2(x2)\n",
    "        x3 = self.conv3(x)\n",
    "        x3 = self.conv4(x3)\n",
    "        x3 = self.conv5(x3)\n",
    "        x = torch.cat((x1, x2, x3), dim=1)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class InceptionC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(InceptionC, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(1920, 192, kernel_size=1)\n",
    "        self.conv2 = nn.Conv3d(1920, 128, kernel_size=1)\n",
    "        self.conv3 = nn.Conv3d(128, 192, kernel_size=[3, 1, 1], padding=[1, 0, 0])\n",
    "        self.conv4 = nn.Conv3d(192, 224, kernel_size=[1, 3, 1], padding=[0, 1, 0])\n",
    "        self.conv5 = nn.Conv3d(224, 256, kernel_size=[1, 1, 3], padding=[0, 0, 1])\n",
    "        self.conv6 = nn.Conv3d(448, 1920, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.conv2(x)\n",
    "        x2 = self.conv3(x2)\n",
    "        x2 = self.conv4(x2)\n",
    "        x2 = self.conv5(x2)\n",
    "        x3 = torch.cat((x1, x2), dim=1)\n",
    "        x3 = self.conv6(x3)\n",
    "        x = x + x3\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class GoogLeNet(nn.Module):\n",
    "    def __init__(self, layerA=5, layerB=10, layerC=5):\n",
    "        super(GoogLeNet, self).__init__()\n",
    "        self.layerA = layerA\n",
    "        self.layerB = layerB\n",
    "        self.layerC = layerC\n",
    "        self.stem = Stem()\n",
    "        self.inceptionA = nn.ModuleList([InceptionA() for i in range(layerA)])\n",
    "        self.reductionA = ReductionA()\n",
    "        self.inceptionB = nn.ModuleList([InceptionB() for i in range(layerB)])\n",
    "        self.reductionB = ReductionB()\n",
    "        self.inceptionC = nn.ModuleList([InceptionC() for i in range(layerC)])\n",
    "        self.avgpool = nn.AvgPool3d(kernel_size=4)\n",
    "        self.dropout = nn.Dropout(0.8, inplace=True)\n",
    "        self.output = nn.Sequential(\n",
    "                nn.Conv3d(1920, 512, kernel_size=1),\n",
    "                nn.Conv3d(512, 1, kernel_size=1)\n",
    "            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        for i in range(self.layerA):\n",
    "            x = self.inceptionA[i](x)\n",
    "        x = self.reductionA(x)\n",
    "        x1 = x.clone()\n",
    "        for i in range(self.layerB):\n",
    "            x = self.inceptionB[i](x)\n",
    "        x = self.reductionB(x)\n",
    "        x2 = x.clone()\n",
    "        for i in range(self.layerC):\n",
    "            x = self.inceptionC[i](x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.output(x)\n",
    "        return x, x1, x2\n",
    "        \n",
    "net = GoogLeNet()\n",
    "for voxel in masked_voxel_loader:\n",
    "    x, x1, x2 = net(voxel.to(dtype=torch.float32).unsqueeze(1))\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
